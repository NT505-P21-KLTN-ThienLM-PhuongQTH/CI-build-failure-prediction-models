{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Import helper modules\n",
    "sys.path.append(\"../src\")\n",
    "from utils import helpers\n",
    "from optimization import GA_runner\n",
    "# Paths\n",
    "MODEL_DIR = \"../models/single_lstm\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = helpers.get_dataset(\"apache_jackrabbit-oak.csv\")\n",
    "print(\"Dataset info:\")\n",
    "print(dataset.info())\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets, test_sets = helpers.online_validation_folds(dataset)\n",
    "print(f\"Number of train folds: {len(train_sets)}, test folds: {len(test_sets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocess(dataset_train, time_step):\n",
    "    feature_cols = [col for col in dataset_train.columns if col not in ['gh_build_started_at', 'gh_project_name'] and dataset_train[col].dtype != 'O']\n",
    "    training_set = dataset_train[feature_cols].values\n",
    "    y = dataset_train['build_failed'].values\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    training_set = scaler.fit_transform(training_set)\n",
    "    print(f\"Scaled min/max: {training_set.min()}, {training_set.max()}\")\n",
    "\n",
    "    print(\"Class distribution BEFORE SMOTE:\")\n",
    "    print(pd.Series(y).value_counts(normalize=True))\n",
    "\n",
    "    if helpers.CONFIG.get('WITH_SMOTE', True):\n",
    "        smote = SMOTE(random_state=42)\n",
    "        training_set, y = smote.fit_resample(training_set, y)\n",
    "        print(\"Applied SMOTE.\")\n",
    "\n",
    "    print(\"Class distribution AFTER SMOTE:\")\n",
    "    print(pd.Series(y).value_counts(normalize=True))\n",
    "\n",
    "    X_train = np.lib.stride_tricks.sliding_window_view(training_set, (time_step, training_set.shape[1]))[:-1]\n",
    "    X_train = np.squeeze(X_train, axis=1)\n",
    "    y_train = y[time_step:]\n",
    "\n",
    "    print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "    return X_train, y_train, scaler\n",
    "\n",
    "def test_preprocess(train_set, test_set, time_step, scaler):\n",
    "    feature_cols = [col for col in train_set.columns if col not in ['gh_build_started_at', 'gh_project_name'] and train_set[col].dtype != 'O']\n",
    "    train_scaled = scaler.transform(train_set[feature_cols])\n",
    "    test_scaled = scaler.transform(test_set[feature_cols])\n",
    "    dataset_total = np.vstack((train_scaled, test_scaled))\n",
    "    inputs = dataset_total[-(len(test_set) + time_step):]\n",
    "\n",
    "    X_test = np.lib.stride_tricks.sliding_window_view(inputs, (time_step, inputs.shape[1]))[:-1]\n",
    "    X_test = np.squeeze(X_test, axis=1)\n",
    "    y_test = test_set['build_failed'].values\n",
    "    print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_lstm_model(network_params, train_set):\n",
    "    X_train, y_train, scaler = train_preprocess(train_set, network_params['time_step'])\n",
    "    drop = network_params['drop_proba']\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        LSTM(units=network_params['nb_units'], return_sequences=(network_params['nb_layers'] > 1)),\n",
    "        Dropout(drop),\n",
    "        *[\n",
    "            layer for i in range(1, network_params['nb_layers'])\n",
    "            for layer in (LSTM(units=network_params['nb_units'], return_sequences=(i < network_params['nb_layers'] - 1)), Dropout(drop))\n",
    "        ],\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=network_params['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=y_train)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=network_params['nb_epochs'],\n",
    "                        batch_size=network_params['nb_batch'], callbacks=[es], class_weight=class_weight_dict)\n",
    "\n",
    "    # Plot loss curve\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title(\"Loss over epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    validation_loss = np.min(history.history['val_loss'])\n",
    "    entry = Utils.predict_lstm(model, X_train, y_train)\n",
    "    entry['validation_loss'] = validation_loss\n",
    "\n",
    "    model_path = os.path.join(MODEL_DIR, f\"lstm_{network_params['nb_units']}_{network_params['nb_layers']}.keras\")\n",
    "    model.save(model_path)\n",
    "    with open(os.path.join(MODEL_DIR, 'scaler.pkl'), 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "    return {'validation_loss': validation_loss, 'model': model, 'entry': entry, 'scaler': scaler}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run GA Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, model, result = None, None, None\n",
    "start = timer()\n",
    "all_params = {\n",
    "    'drop_proba': list(np.linspace(0.01, 0.2, 5)),\n",
    "    'nb_units': [32, 64],\n",
    "    'nb_epochs': [5],\n",
    "    'nb_batch': [16],\n",
    "    'nb_layers': [1, 2],\n",
    "    'optimizer': ['adam'],\n",
    "    'time_step': list(range(5, 15))\n",
    "}\n",
    "params, model, result = GA_runner.generate(all_params, construct_lstm_model, train_sets[0])\n",
    "end = timer()\n",
    "\n",
    "print(\"Training complete in {:.2f}s\".format(end - start))\n",
    "print(\"Best parameters:\", params)\n",
    "print(\"Train Results:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_preprocess(train_sets[0], test_sets[0], params['time_step'], result['scaler'])\n",
    "test_result = Utils.predict_lstm(result['model'], X_test, y_test)\n",
    "print(\"Test Results:\", test_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-build",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
