{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Setup Environment"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import logging\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Analyze Data\n",
    "### 2.1. Check for missing values follow the column"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined_df = pd.read_csv(\"../data/combined/combined_travistorrent.csv\")\n",
    "combined_df.isna().mean()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2. Check for missing values follow the row"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nan_per_row = combined_df.isna().sum(axis=1)\n",
    "\n",
    "# Count frequency and calculate ratio\n",
    "nan_counts = nan_per_row.value_counts().sort_index()\n",
    "nan_ratios = nan_counts / len(combined_df)\n",
    "\n",
    "# Create DataFrame for tabular display\n",
    "table_df = pd.DataFrame({\n",
    "    'NaN columns number': nan_counts.index,\n",
    "    'Row number': nan_counts.values,\n",
    "    'Ratio (%)': (nan_ratios * 100).values\n",
    "})\n",
    "\n",
    "# Làm tròn tỷ lệ\n",
    "table_df['Ratio (%)'] = table_df['Ratio (%)'].round(2)\n",
    "\n",
    "# In bảng\n",
    "print(\"\\nTable of ratio of rows by number of NaN columns:\")\n",
    "print(table_df)\n",
    "\n",
    "# Vẽ biểu đồ tròn\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.pie(table_df['Ratio (%)'], labels=table_df['NaN columns number'], autopct='%1.1f%%', startangle=140,\n",
    "        colors=plt.cm.Paired.colors)\n",
    "plt.title('Ratio of rows to number of columns NaN')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Tìm số lượng cột NaN nhiều nhất\n",
    "max_nan = nan_per_row.max()\n",
    "max_nan_count = nan_counts.get(max_nan, 0)\n",
    "max_nan_ratio = nan_ratios.get(max_nan, 0)\n",
    "\n",
    "print(\n",
    "    f\"\\nThe row with the most NaN columns: {max_nan} NaN columns, with {max_nan_count} rows, ratio: {max_nan_ratio * 100:.2f}%\")\n",
    "# Remove rows with 17 NaN values\n",
    "nan_per_row = combined_df.isna().sum(axis=1)\n",
    "cleaned_df = combined_df[nan_per_row != 17]\n",
    "combined_df.rename(columns={\"tr_status\": \"build_failed\"}, inplace=True)\n",
    "combined_df = combined_df[combined_df[\"build_failed\"].isin([\"passed\", \"failed\"])].copy()\n",
    "combined_df[\"build_failed\"] = combined_df[\"build_failed\"].map({\"passed\": 0, \"failed\": 1})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3. Các dòng có 1 và 3 cột NaN"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.3.2. Lọc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rows_with_1_nan = combined_df[nan_per_row == 1].copy()\n",
    "rows_with_3_nan = combined_df[nan_per_row == 3].copy()\n",
    "\n",
    "\n",
    "# Hàm để phân tích và hiển thị dưới dạng bảng\n",
    "def analyze_nan_rows(df, num_nan):\n",
    "    \"\"\"\n",
    "    Phân tích các dòng có `num_nam` cột NaN, in ra tên các cột đó và giá trị của 'tr_status' hoặc 'build_failed'.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame chứa dữ liệu.\n",
    "        num_nan: Số lượng cột NaN cần trên 1 dòng.\n",
    "    \"\"\"\n",
    "    if len(df) == 0:\n",
    "        print(f\"\\nKhông có dòng nào có {num_nan} cột NaN.\")\n",
    "        return\n",
    "\n",
    "    # Tạo cột mới chứa danh sách các cột có NaN\n",
    "    nan_cols = df.isna()\n",
    "    df['NaN Columns'] = nan_cols.apply(lambda row: tuple(col for col, is_nan in row.items() if is_nan), axis=1)\n",
    "\n",
    "    status_col = 'build_failed'\n",
    "    if status_col not in df.columns:\n",
    "        print(f\"\\nKhông tìm thấy cột 'build_failed' trong dữ liệu.\")\n",
    "        return\n",
    "\n",
    "    # Nhóm các dòng theo tập hợp các cột NaN giống nhau\n",
    "    grouped = df.groupby('NaN Columns')\n",
    "\n",
    "    table_data = []\n",
    "    possible_statuses = [0, 1]  # Giá trị của build_failed: 0 (thành công), 1 (thất bại)\n",
    "\n",
    "    for nan_cols_group, group in grouped:\n",
    "        row_count = len(group)\n",
    "\n",
    "        # Đếm phân bố giá trị của status_col\n",
    "        status_counts = group[status_col].value_counts()\n",
    "\n",
    "        # Tạo một hàng cho bảng\n",
    "        row = {\n",
    "            'NaN Columns': ', '.join(nan_cols_group),\n",
    "            'Row Count': row_count\n",
    "        }\n",
    "\n",
    "        # Thêm các cột cho từng giá trị của status_col, điền 0 nếu không có giá trị\n",
    "        for status in possible_statuses:\n",
    "            row[f'Build {status}'] = status_counts.get(status, 0)\n",
    "\n",
    "        table_data.append(row)\n",
    "\n",
    "    # Tạo DataFrame từ table_data\n",
    "    result_table = pd.DataFrame(table_data)\n",
    "\n",
    "    # Sắp xếp lại cột\n",
    "    columns_order = ['NaN Columns', 'Row Count'] + [f'Build {status}' for status in possible_statuses]\n",
    "    result_table = result_table[columns_order]\n",
    "\n",
    "    return result_table\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.3.2. Phân tích"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "analyze_nan_rows(rows_with_1_nan, 1)\n",
    "analyze_nan_rows(rows_with_3_nan, 3)\n",
    "table_1_nan = analyze_nan_rows(rows_with_1_nan, 1)\n",
    "table_3_nan = analyze_nan_rows(rows_with_3_nan, 3)\n",
    "print(table_1_nan)\n",
    "print(table_3_nan)\n",
    "print(\"\\nPhân tích tương quan với build failure:\")\n",
    "\n",
    "columns_to_analyze = ['git_num_commits', 'gh_num_issue_comments', 'gh_num_pr_comments']\n",
    "\n",
    "\n",
    "def calculate_failure_rate(df, col_name):\n",
    "    \"\"\"\n",
    "    Tính tỷ lệ build failure cho một cột cụ thể trong DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame chứa dữ liệu.\n",
    "        col_name: Tên cột cần phân tích.\n",
    "\n",
    "    Returns:\n",
    "        float: Tỷ lệ build failure (%).\n",
    "    \"\"\"\n",
    "    total = len(df)\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    failed = len(df[df['build_failed'] == 1])\n",
    "    return round(failed / total * 100, 2)\n",
    "\n",
    "\n",
    "# Tạo danh sách để lưu dữ liệu bảng\n",
    "table_data = []\n",
    "\n",
    "# Phân tích có/không NaN\n",
    "for col in columns_to_analyze:\n",
    "    # Nhóm có NaN\n",
    "    rows_with_nan = combined_df[combined_df[col].isna()]\n",
    "    failure_rate_with_nan = calculate_failure_rate(rows_with_nan, col)\n",
    "    rows_with_nan_count = len(rows_with_nan)\n",
    "\n",
    "    # Nhóm không có NaN\n",
    "    rows_without_nan = combined_df[combined_df[col].notna()]\n",
    "    failure_rate_without_nan = calculate_failure_rate(rows_without_nan, col)\n",
    "    rows_without_nan_count = len(rows_without_nan)\n",
    "\n",
    "    # Tính hệ số tương quan (chỉ với các dòng không có NaN)\n",
    "    correlation = None\n",
    "    if len(rows_without_nan) > 0:\n",
    "        correlation = rows_without_nan[[col, 'build_failed']].corr().iloc[0, 1]\n",
    "\n",
    "    # Thêm hàng vào bảng\n",
    "    table_data.append({\n",
    "        'Column': col,\n",
    "        'Rows with NaN': rows_with_nan_count,\n",
    "        'Failure Rate (NaN)': failure_rate_with_nan,\n",
    "        'Rows without NaN': rows_without_nan_count,\n",
    "        'Failure Rate (Not NaN)': failure_rate_without_nan,\n",
    "        'Correlation': correlation\n",
    "    })\n",
    "\n",
    "# Tạo DataFrame từ table_data\n",
    "result_table = pd.DataFrame(table_data)\n",
    "\n",
    "# Định dạng cột Correlation\n",
    "result_table['Correlation'] = result_table['Correlation'].apply(lambda x: f\"{x:.4f}\" if x is not None else \"N/A\")\n",
    "\n",
    "# In bảng\n",
    "print(\"\\nBảng phân tích tương quan với build failure:\")\n",
    "print(result_table)\n",
    "\n",
    "# Vẽ biểu đồ so sánh tỷ lệ build failure\n",
    "failure_rates = []\n",
    "labels = []\n",
    "for col in columns_to_analyze:\n",
    "    rows_with_nan = combined_df[combined_df[col].isna()]\n",
    "    rows_without_nan = combined_df[combined_df[col].notna()]\n",
    "    failure_rates.extend([\n",
    "        calculate_failure_rate(rows_with_nan, col),\n",
    "        calculate_failure_rate(rows_without_nan, col)\n",
    "    ])\n",
    "    labels.extend([f\"{col} (NaN)\", f\"{col} (Not NaN)\"])\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(labels, failure_rates, color=['#ff9999', '#66b3ff'] * len(columns_to_analyze))\n",
    "plt.xlabel('Cột và trạng thái NaN')\n",
    "plt.ylabel('Tỷ lệ build failure (%)')\n",
    "plt.title('Tỷ lệ build failure: Có NaN vs Không NaN')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Data Processing"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1. Preprocess"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Replace NaN values with default values\n",
    "columns_required = [\"build_failed\", \"gh_project_name\",\n",
    "                    \"gh_build_started_at\"]  # Only columns can not fill with default values\n",
    "before_drop = len(combined_df)\n",
    "combined_df.fillna(0, inplace=True)\n",
    "print(f\"\\nDropped {before_drop - len(combined_df)} rows missing critical columns. New shape: {combined_df.shape}\")\n",
    "\n",
    "combined_df['gh_build_started_at'] = pd.to_datetime(combined_df['gh_build_started_at'])\n",
    "# Group job by project_name, build_started_at, and build_failed\n",
    "builds_df = combined_df.groupby([\n",
    "    'gh_project_name',\n",
    "    'gh_build_started_at',\n",
    "    'build_failed'\n",
    "], as_index=False).agg({\n",
    "    'git_num_commits': 'sum',\n",
    "    'gh_num_issue_comments': 'sum',\n",
    "    'gh_num_pr_comments': 'sum',\n",
    "    'gh_team_size': 'mean',\n",
    "    'gh_sloc': 'mean',\n",
    "    'git_diff_src_churn': 'sum',\n",
    "    'git_diff_test_churn': 'sum',\n",
    "    'gh_diff_files_added': 'sum',\n",
    "    'gh_diff_files_deleted': 'sum',\n",
    "    'gh_diff_files_modified': 'sum',\n",
    "    'gh_diff_tests_added': 'sum',\n",
    "    'gh_diff_tests_deleted': 'sum',\n",
    "    'gh_diff_src_files': 'sum',\n",
    "    'gh_diff_doc_files': 'sum',\n",
    "    'gh_diff_other_files': 'sum',\n",
    "    'gh_num_commits_on_files_touched': 'sum',\n",
    "    'gh_test_lines_per_kloc': 'mean',\n",
    "    'gh_test_cases_per_kloc': 'mean',\n",
    "    'gh_asserts_cases_per_kloc': 'mean',\n",
    "    'gh_is_pr': 'max',\n",
    "    'gh_by_core_team_member': 'max',\n",
    "    'gh_num_commit_comments': 'sum'\n",
    "})\n",
    "print(f\"\\nThe amount of data reduced after grouping: {combined_df.shape[0] - builds_df.shape[0]}\")\n",
    "print(f\"\\nShape after merging jobs into builds: {builds_df.shape}\")\n",
    "\n",
    "# Drop duplicates\n",
    "num_duplicates = builds_df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicates: {num_duplicates}\")\n",
    "initial_rows = len(builds_df)\n",
    "builds_df.drop_duplicates(inplace=True)\n",
    "print(f\"\\nDropped {initial_rows - len(builds_df)} duplicates. New shape: {builds_df.shape}\")\n",
    "\n",
    "# Check if DataFrame is empty after duplicates\n",
    "if builds_df.empty:\n",
    "    raise ValueError(\"DataFrame is empty after dropping duplicates. Check duplicate criteria or data quality.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.2. Convert data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Encode categorical columns\n",
    "categorical_columns = [\"gh_is_pr\", \"gh_by_core_team_member\"]\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    if col in builds_df.columns:\n",
    "        le = LabelEncoder()\n",
    "        builds_df[col] = le.fit_transform(builds_df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    else:\n",
    "        print(f\"Column {col} not found in the dataset. Skipping...\")\n",
    "\n",
    "# Normalize numerical columns\n",
    "numerical_columns = [\n",
    "    \"git_num_commits\",\n",
    "    \"gh_num_commit_comments\",\n",
    "    \"git_diff_src_churn\",\n",
    "    \"git_diff_test_churn\",\n",
    "    \"gh_diff_files_added\",\n",
    "    \"gh_diff_files_deleted\",\n",
    "    \"gh_diff_files_modified\",\n",
    "    \"gh_diff_tests_added\",\n",
    "    \"gh_diff_tests_deleted\",\n",
    "    \"gh_diff_src_files\",\n",
    "    \"gh_diff_doc_files\",\n",
    "    \"gh_diff_other_files\",\n",
    "    \"gh_num_commits_on_files_touched\",\n",
    "    \"gh_sloc\",\n",
    "    \"gh_test_lines_per_kloc\",\n",
    "    \"gh_test_cases_per_kloc\",\n",
    "    \"gh_asserts_cases_per_kloc\",\n",
    "    \"gh_team_size\",\n",
    "    \"gh_num_issue_comments\",\n",
    "    \"gh_num_pr_comments\"\n",
    "]\n",
    "scaler = MinMaxScaler()\n",
    "builds_df[numerical_columns] = scaler.fit_transform(builds_df[numerical_columns].fillna(0))\n",
    "print(\"\\nDataset after encoding and normalization:\")\n",
    "print(builds_df.head())\n",
    "print(f\"Final shape: {builds_df.shape}\")\n",
    "# Print imbalance information\n",
    "imbalance = builds_df['build_failed'].value_counts(normalize=True)\n",
    "print(\"Class distribution:\")\n",
    "print(imbalance)\n",
    "\n",
    "# Plot class distribution\n",
    "imbalance.plot(kind='bar', title='Class Distribution (build_failed)')\n",
    "plt.xlabel('Class (0: Passed, 1: Failed)')\n",
    "plt.ylabel('Proportion')\n",
    "plt.show()\n",
    "\n",
    "project_counts = builds_df['gh_project_name'].value_counts()\n",
    "# Calculate class distribution for each project\n",
    "balance_data = []\n",
    "for project in project_counts.index:\n",
    "    project_df = builds_df[builds_df['gh_project_name'] == project]\n",
    "    class_counts = project_df['build_failed'].value_counts(normalize=True)\n",
    "    failed_ratio = class_counts.get(1.0, 0.0)\n",
    "    passed_ratio = class_counts.get(0.0, 0.0)\n",
    "    if 0.2 <= passed_ratio <= 0.8 and 0.2 <= failed_ratio <= 0.8:\n",
    "        balance_data.append({\n",
    "            'project': project,\n",
    "            'failed_ratio': failed_ratio,\n",
    "            'passed_ratio': passed_ratio,\n",
    "            'total_rows': len(project_df)\n",
    "        })\n",
    "\n",
    "# Create DataFrame and sort by failed ratio\n",
    "balance_df = pd.DataFrame(balance_data)\n",
    "balance_df = balance_df.sort_values(by='total_rows', ascending=False).head(10)\n",
    "\n",
    "print(\"Top 10 Projects with Balanced Class Distribution (30%-70%):\")\n",
    "print(balance_df[['project', 'failed_ratio', 'passed_ratio', 'total_rows']])\n",
    "\n",
    "# Plot top 10 projects by number of rows\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(balance_df['project'], balance_df['total_rows'], color='lightblue')\n",
    "plt.title('Top 10 Projects by Number of Rows (Balanced Class Distribution)')\n",
    "plt.xlabel('Project Name')\n",
    "plt.ylabel('Number of Rows')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot class distribution for top 10 projects\n",
    "plt.figure(figsize=(14, 6))\n",
    "bar_width = 0.4\n",
    "x = np.arange(len(balance_df))\n",
    "\n",
    "plt.bar(x - bar_width / 2, balance_df['passed_ratio'], width=bar_width, label='Passed (0)', color='skyblue')\n",
    "plt.bar(x + bar_width / 2, balance_df['failed_ratio'], width=bar_width, label='Failed (1)', color='salmon')\n",
    "\n",
    "plt.xticks(ticks=x, labels=balance_df['project'], rotation=45, ha='right')\n",
    "plt.xlabel('Project Name')\n",
    "plt.ylabel('Class Ratio')\n",
    "plt.title('Class Distribution in Top 10 Projects (Balanced 30%-70%)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Print class distribution for top 10 projects\n",
    "print(balance_df[['project', 'failed_ratio', 'passed_ratio', 'total_rows']].sort_index())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Save data by project"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output_data_dir = \"../data/processed\"\n",
    "top_projects = balance_df['project']\n",
    "for project in top_projects:\n",
    "    project_df = builds_df[builds_df['gh_project_name'] == project]\n",
    "    file_name = project.replace(\"/\", \"_\").replace(\":\", \"_\").replace(\" \", \"_\") + \".csv\"\n",
    "    project_df.to_csv(os.path.join(output_data_dir, file_name), index=False)\n",
    "    print(f\"Saved {file_name} with {len(project_df)} rows\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-build",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
